{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qpi2zTwUrh9I"
   },
   "source": [
    "# ELEN90088 System Optimisation and Machine Learning, 2025\n",
    "\n",
    "# Exercise 1  \n",
    "## Due date: <u> 23:59, Monday the 31st March, 2025 </u>\n",
    "\n",
    "## Submission guidline:\n",
    "\n",
    "* One submission per group by the due date on LMS.\n",
    "* Answer the exercise questions in this Python notebook itself.\n",
    "* Export your notebook file (.ipynb) as a PDF file, on which we give marks and comments. This means that each group should submit two versions of the exercise report (.ipynb file and PDF).\n",
    "* Demonstrators will conduct a brief oral assessment for selected groups in subsequent workshop. Details will be announced on LMS.\n",
    "* Regarding the use of LLM and other generative AI tools: refer to information in the introductory slides.\n",
    "* This exercise contains one question (Question 7) with $2$ bonus marks. So the highest marks you could obtain from this Exercise are $10+2=12$ marks.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k2I55S9fsrCZ"
   },
   "source": [
    "## Question 1 (plot convex and non-convex functions) (Mark: 1 point)\n",
    "\n",
    "### Practice Question\n",
    "Plot one concave and one non-convex (neither convex nor concave) function of your choosing (preferably one in 2 dimensions and the other in 3 dimensions so that it can be visualised, check e.g. [this tutorial](https://matplotlib.org/2.0.2/mpl_toolkits/mplot3d/tutorial.html) for hints). Provide their formulas below.\n",
    "\n",
    "*Hint: an interesting and well-known function is [Rosenbrock function].(https://en.wikipedia.org/wiki/Rosenbrock_function)* It is already built-in to [Scipy optimize](https://docs.scipy.org/doc/scipy/reference/optimize.html#benchmark-problems) as a benchmark. *You can keep your answer simple and don't need to spend too much time on this practice question.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two-dimensional functions:\n",
    "\n",
    "<img src=\"./figures/Q1_1.png\" width=\"50%\">\n",
    "\n",
    "Three-dimensional functions:\n",
    "\n",
    "<img src=\"./figures/Q1_2.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# 3D plots\n",
    "# Define the Rosenbrock function\n",
    "def rosenbrock(x, y, a=1, b=100):\n",
    "    return (a - x)**2 + b * (y - x**2)**2\n",
    "\n",
    "# Define y = x^2 function\n",
    "def parabola(x):\n",
    "    return x**2\n",
    "\n",
    "# Create grid\n",
    "x = np.linspace(-2, 2, 400)\n",
    "y = np.linspace(-2, 2, 400)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "# Compute Rosenbrock function values\n",
    "Z_rosenbrock = rosenbrock(X, Y)  # non-convex nor concave\n",
    "\n",
    "# Compute y = x^2 function values\n",
    "Z_parabola = parabola(X) #convex\n",
    " \n",
    "# Create 3D plot\n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "\n",
    "# Plot Rosenbrock function\n",
    "ax1 = fig.add_subplot(121, projection='3d')\n",
    "ax1.plot_surface(X, Y, Z_rosenbrock, cmap='inferno')\n",
    "ax1.set_title('Rosenbrock Function')\n",
    "ax1.set_xlabel('X')\n",
    "ax1.set_ylabel('Y')\n",
    "ax1.set_zlabel('Z')\n",
    "\n",
    "# Plot y = x^2 function\n",
    "ax2 = fig.add_subplot(122, projection='3d')\n",
    "ax2.plot_surface(X, Y, Z_parabola, cmap='viridis')\n",
    "ax2.set_title('$y = x^2$ Function')\n",
    "ax2.set_xlabel('X')\n",
    "ax2.set_ylabel('Y')\n",
    "ax2.set_zlabel('Z')\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2D plots\n",
    "# Define x values\n",
    "x = np.linspace(-10, 10, 400)\n",
    "\n",
    "# Define y expressions\n",
    "y1 = 10 * x ** 2  # convex\n",
    "y2 = x ** 3 + x ** 2  # non-convex function\n",
    "\n",
    "# Create 2D plot\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(x, y1, label=r'$y = 10x^2 \\quad convex$', linestyle='-', color='b')\n",
    "plt.plot(x, y2, label=r'$y = x^3 + x^2 \\quad not\\ convex$', linestyle='--', color='r')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Plot of $y = 10x^2$ and $y = x^3 + x^2$')\n",
    "\n",
    "# Add grid\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tA1qVfs9tEw0"
   },
   "source": [
    "## Question 2 (decide if a polynomial is convex) (Mark: 2 points)\n",
    "\n",
    "Consider a polynomial with $2$ variable\n",
    "$$\n",
    "p(x)=\\sum_{i,j: i+j\\leq d} c_{ij}x_1^{i}x_2^{j}\n",
    "$$ where the sum is over all nonnegative integer pairs $i,j$ whose sum is less or equal to $d$. We call $d$ the *degree* of the polynomial.\n",
    "\n",
    "To understand the notation better, consider a polynomial of degree $2$ given by $ h(x)= x_1x_2+2x_2^2+3x_1-1$. You should convince yourself that $h(x)$  can be obtained by setting $c_{11}=1, c_{02}=2, c_{10}=3, c_{00}=-1$ and all other coefficients $c_{ij}$ to $0$ in $p(x)$.\n",
    "\n",
    "### Answer the following questions:\n",
    "\n",
    "1. how to decide the convexity of a  first-order ($d=1$) polynomial?\n",
    "2. how to decide the convexity of a  quadratic ($d=2$) polynomial?\n",
    "3. how to decide the convexity of a cubic ($d=3$) polynomial?\n",
    "4. extend the result in (3) to all odd-order ($d$ is odd) polynomial.\n",
    "5. how to decide the convexity of a quartic ($d=4$) polynomial? What is the difference/difficulty compared to the quadratic case? In particular, try to plot a convex quartic polynomial and a concave quartic polynomial in $1$ variable.\n",
    "\n",
    "*Comment: as shown in [this paper](https://web.mit.edu/~a_a_a/Public/Publications/convexity_nphard.pdf), unless NP=P, it is computationally hard to check the convexity of a polynomial with order equal or larger than $4$. So in general, it is computationaly difficult to decide if a function is convex.*\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1\n",
    "The first-order polynomial function can be called as a linear function. $p(x)=c_1*x+c_0$ It's affine, so it can be both convex function and concave function.\n",
    "\n",
    "### 2\n",
    "For d equals to 2, $p(x) = c_2x^2+c_1x+c_0$. By taking the second derivative or using the Hessian matrix, we can identify the function is convex or not. If the Hessian is positive definite, then the function is convex. Also, by taking second derivative, $p''(x)=2c_2$, if $c_2$ is bigger than 0, the function is concave up, which means it is convex. If $c_2$ is smaller than 0, which is concave down, it is concave.\n",
    "\n",
    "### 3\n",
    "For d equals to 3, $p(x) = c_3x^3+c_2x^2+c_1x+c_0$. Taking the second derivative $p''(x)=6c_3x+6c_2$, it turns to a linear function which make the sign change when we vary the value of x. Then, the sign of $c_3$ becomes less important for the convexity of the function as x increasing function changing from convex to concave or opposite. Therefore, cubic polynomial can only be partial convex or concave.\n",
    "\n",
    "### 4\n",
    "Odd-order polynomials (degree 3, 5, etc.) generally have convex regions and concave region. As x increasing, the sign of $p''(x)$ transforms between positive and negative. Therefore, the convexity depends on the roots and signs of the second derivative. They are not convex or concave globally.\n",
    "\n",
    "### 5\n",
    "For d equals to 4, $p(x) = c_4x^4+c_3x^3+c_2x^2+c_1x+c_0$. The second derivative is $p''(x)=12c_4x^2+6c_3$. If $c_4$ is bigger than 0, no matter how value x varying, $p''(x)$ will always be positve. The function is convex. Otherwise, the function is concave. (ignore $c_4=0$) Also, $c_4$ is important, because it can shift $p''(x)$ to the negative part of y-axis which makes the convexity of the function depending on the x value. As long as values of $p''(x)$ are all above the x-axis, $c_4$ can be any number. \n",
    "The difference compared to quadratic case is that for quadratic case, we only need to consider the value for $c_2$, but for quartic case, both $c_4$ and $c_3$ should be considered. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g_G0jX0rtyM2"
   },
   "source": [
    "## Question 3 (Optimization package) (Mark: 1 point)\n",
    "\n",
    "[CVXPY](https://www.cvxpy.org/index.html) is an open source Python-embedded modeling language for convex optimization problems. This exercise aims to familiarze you with this package.\n",
    "\n",
    "\n",
    "*Note: you are __not__ required to use CVXPY for your exercises or project. There are other Python-based optimization package you can use, including [Scipy](https://docs.scipy.org/doc/scipy/tutorial/optimize.html) or [Pyomo](https://www.pyomo.org/). If you decide to use a different optimization package, you can solve this exercise with one you choose. CVXPY lets you express your problem in a natural way that follows the math, rather than in the restrictive standard form required by solvers, but it has its own restrictions. In particular, CVXPY does not support non-convex optimization whereas other packages (e.g. Scipy) does.*\n",
    "\n",
    "\n",
    "Before addressing this problem, we suggest you read through the first section of the [User Guide](https://www.cvxpy.org/tutorial/index.html) and a few [Basic examples](https://www.cvxpy.org/examples/index.html). They should already give you a pretty good idea how a convex optimization problem can be solved using CVXPY.\n",
    "\n",
    "Consider a simple scalar linear dynamical system\n",
    "$$\n",
    "x_{t+1}=ax_t+ u_t, \\quad t=1,2,\\ldots\n",
    "$$ where $|a|>1$. We call $x_t$ the state of the system, and $u_t$ the control input. The objective is to minimize the cost $C$ defined as\n",
    "$$\n",
    "C=\\sum_{t=1}^T x_t^2+\\sum_{t=1}^{T-1}\\alpha u_t^2.\n",
    "$$\n",
    "\n",
    "Given the parameters $x_1=1, a=1.5, \\alpha =2$,  and $T=3$, find the optimal control input $u_1, u_2$ that minimizes the cost by rewriting the problem as a [quadratic optimization problem](https://www.cvxpy.org/examples/basic/quadratic_program.html).\n",
    "\n",
    "*Hint: there are at least two ways to formulate your problem: you can  formulate a problem where the optimization variable is just $(u_1, u_2)$; you can also formulate a problem where the optimization variable is $(u_1, u_2, x_1, x_2, x_3)$. See if you can use the second (more interesting) problem formulation.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$C=\\sum_{t=1}^T x_t^2+\\sum_{t=1}^{T-1}\\alpha u_t^2,\\quad \\alpha=2, T=3$\n",
    "\n",
    "Based on this equation, $C=\\sum_{t=1}^3 x_t^2+\\sum_{t=1}^{2}2 u_t^2$\n",
    "\n",
    "$C=x_1^2 + x_2^2 + x_3^2 + 2u_1^2 + 2u_2^2 $\n",
    "\n",
    "$x_{t+1}=ax_t+ u_t, \\quad t=1,2,\\ldots ,\\quad x_1=1, a=1.5, \\alpha =2$,  and $T=3$\n",
    "\n",
    "When $t =1,\\quad x_2 = 1.5x_1+u_1 = 1.5+u_1$ $\\quad$\n",
    "\n",
    "When $t =2, \\quad x_3= 15x_2 +u_2 = 1.5^2 +1.5u_1 + u_2 = 1.5^2 + 1.5u_1 + u_2$\n",
    "\n",
    "Therefore, $C=1^2 + (1.5+u_1)^2 + (1.5^2 + 1.5u_1 + u_2)^2 + 2u_1^2 + 2u_2^2 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "\n",
    "# Define the variables\n",
    "u_1 = cp.Variable()\n",
    "u_2 = cp.Variable()\n",
    "\n",
    "# Define the objective function\n",
    "c = 1 + (1.5 + u_1)**2 + (2.25 + 1.5*u_1 + u_2)**2 + 2*u_1**2 + 2*u_2**2\n",
    "\n",
    "# Formulate the problem\n",
    "objective = cp.Minimize(c)\n",
    "problem = cp.Problem(objective)\n",
    "\n",
    "# Solve the problem\n",
    "problem.solve()\n",
    "\n",
    "# Print the results\n",
    "print(\"Optimal value of u_1:\", u_1.value)\n",
    "print(\"Optimal value of u_2:\", u_2.value)\n",
    "print(\"Minimum value of c:\", c.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "\n",
    "# Define parameters\n",
    "T = 3\n",
    "a = 1.5\n",
    "alpha = 2\n",
    "\n",
    "def compute_c_function(T):\n",
    "    # Define variables\n",
    "    u = cp.Variable(T-1)  # Control variable u_t\n",
    "    x = cp.Variable(T)  # State variable x_t\n",
    "\n",
    "    # Constraints\n",
    "    # As we know the value of x, it can be seen as a constraint\n",
    "    constraints = [x[0] == 1]  # Initial condition\n",
    "    for t in range(1, T):\n",
    "        constraints.append(x[t] == a * x[t-1] + u[t-1])  # Add new constraints to constraints\n",
    "\n",
    "    # Define the cost function\n",
    "    c = cp.sum_squares(x) + alpha*cp.sum_squares(u)\n",
    "\n",
    "    return c, u, constraints  # Return function, control variable, and constraints\n",
    "\n",
    "# Get function c(u), variable u, and constraints\n",
    "c, u, constraints = compute_c_function(T)\n",
    "\n",
    "# Solve the optimization problem\n",
    "prob = cp.Problem(cp.Minimize(c), constraints)\n",
    "prob.solve()\n",
    "\n",
    "print(\"Optimal value of u:\", u.value)\n",
    "print(\"Minimum value of c:\", c.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "acdVdCsjtfri"
   },
   "source": [
    "## Question 4 (Aloha communication protocol) (Mark: 2 points)\n",
    "\n",
    "**Aloha** is a well-known random access or _MAC_ (Media/multiple Access Control) communication protocol. It enables multiple nodes to share a broadcast channel without any additional signaling in a distributed manner. Unlike _FDMA_ or _TDMA_ (frequency or time-division multiple access), the channel is not divided into segments beforehand and collisions of packets due to simultaneous transmissions by nodes are allowed.\n",
    "\n",
    "In slotted Aloha, the nodes can only transmit at the beginning of time slots, which are kept by a global/shared clock. The operations of slotted ALOHA in each node are decribed as follows:\n",
    "\n",
    "* If there is only one frame in a slot, then the transmission is successful and the slot is said to be a successful slot.\n",
    "* If two or more frames collide in a slot, then the transmission is failed and a re-transmission is considered for each frame involved in the collision. The node will retransmit its frame in each subsequent slot with probability $p$ until the frame is transmitted without a collision, where $0 \\leq p \\leq 1$.\n",
    "\n",
    "Assume that there are $N$ nodes and each node independently attempts to transmit a frame in each slot with probability $p$. For one slot, let $S$ denote the _success probability_ that this slot is a successful slot.\n",
    "\n",
    "### Answer the following questions:\n",
    "1. Provide an expression of $S$ defined above.\n",
    "2. To maximise the $S$, define the optimisation problem to find the optimal value $p$. Note that the constraint $0 \\leq p \\leq 1$\n",
    "should be taken into consideration. Clearly identify the objective and decision variable(s). Is the objective convex or concave? Show through derivation. Find the optimality conditions for this problem.\n",
    "3. When $N$ tends to infinity, what is the maximal success probability $S$?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1\n",
    "$S=N\\cdot p\\cdot (1-p)^{N-1}$\n",
    "\n",
    "### 2\n",
    "Objective function: $S(p)=N\\cdot p\\cdot (1-p)^{N-1}$\n",
    "\n",
    "Decision variable: $p$\n",
    "\n",
    "Constraint: $0\\leq p\\leq1$\n",
    "\n",
    "Because the first derivative $S'(p)=N\\cdot(1-p)^{N-2}\\cdot(1-pN)$ and the second derivative $S''(p)=N\\cdot(1-p)^{N-3}\\cdot(N-1)(pN-2)$. When $p>\\frac{2}{N}$, $S''(p)>0$, $S(p)$ is convex. When $p<\\frac{2}{N}$, $S''(p)<0$, $S(p)$ is concave. However, the optimal solution is $S'(p)=0$ when $p=\\frac{1}{N}$.\n",
    "\n",
    "In conclusion, $S(p)$ is concave when $0\\leq p\\leq\\frac{1}{N}$ and $p=\\frac{1}{N}$ is a global maximum. $S(p)$ is convex when $\\frac{2}{N}<p\\leq1$.\n",
    "\n",
    "<img src=\"./figures/Q4_1.png\" width=\"50%\">\n",
    "\n",
    "### 3\n",
    "When $p=\\frac{1}{N}$, $S_{max}=(1-\\frac{1}{N})^{N-1}$. $\\lim_{N \\to \\infty}(1-\\frac{1}{N})^{N-1}=\\lim_{N \\to \\infty}[(1-\\frac{1}{N})^N\\cdot(1-\\frac{1}{N})^{-1}]=\\frac{1}{e}$. The maximum success probability $S=\\frac{1}{e}$.\n",
    "\n",
    "<img src=\"./figures/Q4_2.png\" width=\"75%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graph(N):\n",
    "    p = np.linspace(0, 1, 1000)\n",
    "    S = N * p * (1 - p)**(N - 1)\n",
    "    plt.plot(p, S, label=f'N = {N}')\n",
    "    plt.xlabel('p', fontsize=14)\n",
    "    plt.ylabel('S', fontsize=14)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def maximum_s(N):\n",
    "    p = 1 / N\n",
    "    S_max = N * p * (1 - p) ** (N - 1)\n",
    "    print(f\"The maximum value of S ≈ {S_max:.6f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    plot_graph(10)\n",
    "    maximum_s(10000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wKrjN_iVtjtX"
   },
   "source": [
    "## Question 5 (Geometric programming: power control in wireless network) (Mark: 2 points)\n",
    "\n",
    "### Example: Power Control in Wireless Communication\n",
    "\n",
    " *Adapted from Boyd, Kim, Vandenberghe, and Hassibi,* \"[A Tutorial on Geometric Programming](https://web.stanford.edu/~boyd/papers/pdf/gp_tutorial.pdf).\"\n",
    "\n",
    "The [power control problem in wireless communications](http://winlab.rutgers.edu/~narayan/PAPERS/PC%20for%20Wireless%20Data.pdf) aims to minimise the total transmitter power available across $N$ trasmitters while concurrently achieving good (or a pre-defined minimum) performance.\n",
    "\n",
    "The technical setup is as follows. Each transmitter $i$ transmits with a power level $P_i$ bounded below and above by a minimum and maximum level. The power of the signal received from transmitter $j$ at receiver $i$ is $G_{ij} P_{j}$, where $G_{ij} > 0$ represents the path gain (often loss) from transmitter $j$ to receiver $i$. The signal power at the intended receiver $i$ is $G_{ii} P_i$, and the interference power at receiver $i$ from other transmitters is given by $\\sum_{k \\neq i} G_{ik}P_k$. The (background) noise power at receiver $i$ is $\\sigma_i$. Thus, the _Signal to Interference and  Noise Ratio (SINR)_ of the $i$th receiver-transmitter pair is\n",
    "\n",
    "$$ S_i = \\frac{G_{ii}P_i}{\\sum_{k \\neq i} G_{ik}P_k + \\sigma_i }. $$\n",
    "\n",
    "The minimum SINR represents a performance lower bound for this system, $S^{\\text min}$.\n",
    "\n",
    "The resulting optimisation problem is formulated as\n",
    "\n",
    "$$\n",
    "\\begin{array}{ll}\n",
    "\\min_{P} & \\sum_{i=1}^N P_i \\\\\n",
    "\\text{subject to} & P^{min} \\leq P_i \\leq P^{max}, \\; \\forall i \\\\\n",
    "& \\dfrac{G_{ii}P_i}{\\sigma_i + \\sum_{k \\neq i} G_{ik}P_k} \\geq S^{min} , \\; \\forall i \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "### Answer the following questions: Wireless Power Control\n",
    "\n",
    "Let $N=10$, $P^{min}=0.1$, $P^{max}=5$, $\\sigma=0.2$ (same for all). Create a random path loss matrix $G$, where off-diagonal elements are between $0.1$ and $0.9$ and the diagonal elements are equal to $1$.\n",
    "1. Convert the problem into standard Geometric Programming form.\n",
    "2. Solve the problem first with $S^{min}=0$, and we recommand to use *cvxpy* or *scipy*. Output and plot the power levels and SINRs that you obtain.\n",
    "3. What happens if you choose an $S^{min}$ that is larger? Solve the problem again and document your results. What happens if you choose a very large $S^{min}$? Observe and comment.\n",
    "4. Suppose that there are only 3 transmitter-receiver pairs, e.g., $N=3$, if the SINR of the $i$th receiver-transmitter pair is\n",
    "\n",
    "$$ S_i = \\frac{G_{ii}P_i}{0.5 \\sum_{j \\neq i}^{N} (G_{ij} P_j \\sum_{k \\neq i, k \\neq j}^{N} G_{ik} P_k )+ \\sigma_i }. $$\n",
    "\n",
    "and other settings remain the same, please try to convert the problem into standard Geometric Programming form again.\n",
    "\n",
    "**Note:**\n",
    "* if you are in the minority of people who have problem installing *cvxpy* or *scipy*, then you can use other packages or even Matlab.\n",
    "* the problem in (1) can be converted to either Geometric Programming or Linear Programming form, while the problem in (4) can not be converted to Linear Programming anymore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1\n",
    "Geometric Programming:\n",
    "\n",
    "\\begin{align*}\n",
    "    \\text{min} \\quad & \\sum_{i=1}^{10} P_i\\\\\n",
    "    \\text{s.t.} \\quad\n",
    "    & \\frac{0.1}{P_i}\\leq 1,\\quad\\forall i \\in \\{1,2,\\dots,N\\}\\\\\n",
    "    & \\frac{P_i}{5}\\leq 1,\\quad\\forall i \\in \\{1,2,\\dots,N\\}\\\\\n",
    "    & \\frac{\\sum_{k \\ne i} G_{ik} P_k + 0.2}{G_{ii}P_i/S^{\\min}}\\leq 1, \\quad \\forall i \\in \\{1, 2, \\dots, N\\} \\\\\n",
    "\\end{align*}\n",
    "\n",
    "### 2\n",
    "Using cvxpy:\n",
    "\n",
    "Poer levels:\n",
    "\n",
    "<img src=\"./figures/Q5_1.png\" width=\"50%\">\n",
    "\n",
    "SINRS:\n",
    "\n",
    "<img src=\"./figures/Q5_3.png\" width=\"50%\">\n",
    "\n",
    "Results of power levels and SINRS:\n",
    "\n",
    "<img src=\"./figures/Q5_2.png\" width=\"75%\">\n",
    "\n",
    "### 3\n",
    "If $S_{\\min}$ becomes larger, $P_i$ and the total power will become larger. If $S_{\\min}$ is very large, the solution might be infeasible.\n",
    "\n",
    "<img src=\"./figures/Q5_4.png\" width=\"75%\">\n",
    "\n",
    "From the graph above, we can observe that $P_i$ becomes larger when $S_{\\min}$ becomes larger. However, when $S_{\\min}>0.24$, the solutions become infeasible.\n",
    "\n",
    "### 4\n",
    "\n",
    "\\begin{align*}\n",
    "    \\text{min} \\quad & \\sum_{i=1}^{3} P_i\\\\\n",
    "    \\text{s.t.} \\quad\n",
    "    & \\frac{0.1}{P_i}\\leq 1,\\quad\\forall i \\in \\{1,2,\\dots,N\\}\\\\\n",
    "    & \\frac{P_i}{5}\\leq 1,\\quad\\forall i \\in \\{1,2,\\dots,N\\}\\\\\n",
    "    & \\frac{0.5(\\sum_  {j \\ne i}^{3} G_{ij} P_{j} \\sum_{k \\ne i, k \\ne j}^{3} G_{ik} P_k)  + 0.2}{G_{ii}P_i/S^{\\min}}\\leq 1, \\quad \\forall i \\in \\{1, 2, \\dots, N\\} \\\\\n",
    "    &  \\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def obj_fun():\n",
    "    # matrix G\n",
    "    np.random.seed(42)\n",
    "    G = np.random.uniform(0.1, 0.9, (N, N))\n",
    "    np.fill_diagonal(G, 1.0)\n",
    "\n",
    "    P = cp.Variable(N, pos=True)\n",
    "    objective = cp.Minimize(cp.sum(P))\n",
    "\n",
    "    # SINR is not a constraint when S_min = 0\n",
    "    constraints = [P >= P_min, P <= P_max]\n",
    "\n",
    "    prob = cp.Problem(objective, constraints)\n",
    "    prob.solve(gp=True)\n",
    "\n",
    "    SINR = [G[i,i] * P.value[i] / (sigma + sum(G[i,k] * P.value[k] for k in range(N) if k != i)) for i in range(N)]\n",
    "\n",
    "    print(\"Power levels: \", P.value)\n",
    "    print(\"SINR: \", SINR)\n",
    "\n",
    "    return P.value, SINR\n",
    "\n",
    "def obj_fun_large_sm(N, P_min, P_max, sigma, S_min):\n",
    "    np.random.seed(42)\n",
    "\n",
    "    G = np.random.uniform(0.1, 0.9, (N, N))\n",
    "    np.fill_diagonal(G, 1.0)\n",
    "\n",
    "    P = cp.Variable(N, pos=True)\n",
    "    objective = cp.Minimize(cp.sum(P))\n",
    "    constraints = [P_min / P <= 1.0, P / P_max <= 1.0]\n",
    "\n",
    "    for i in range(N):\n",
    "        tmp = cp.sum([G[i, k] * P[k] for k in range(N) if k != i])\n",
    "        sinr_inv_expr = (sigma + tmp) / (G[i, i] * P[i])\n",
    "        constraints.append(sinr_inv_expr <= 1.0 / S_min)\n",
    "\n",
    "    prob = cp.Problem(objective, constraints)\n",
    "    prob.solve(gp = True)\n",
    "\n",
    "    print(f\"S_min = {S_min}: Status = {prob.status}, Power levels = {P.value}\")\n",
    "\n",
    "def plot_graph(P_opt, SINR):\n",
    "    plt.figure()\n",
    "    plt.bar(range(N), P_opt)\n",
    "    plt.xlabel('Transmitter Index (N)')\n",
    "    plt.ylabel('Power levels')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.bar(range(N), SINR)\n",
    "    plt.xlabel('Receiver Index (N)')\n",
    "    plt.ylabel('SINR')\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    N = 10\n",
    "    P_min = 0.1\n",
    "    P_max = 5\n",
    "    sigma = 0.2\n",
    "    # S_min = 0\n",
    "    S_min = [0.1, 0.2, 0.23, 0.24, 0.5, 1.0]\n",
    "\n",
    "    # P_opt, SINR = obj_fun()\n",
    "    # plot_graph(P_opt, SINR)\n",
    "    for sm in S_min:\n",
    "        obj_fun_large_sm(N, P_min, P_max, sigma, sm)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PE-Zx2lUt3Y1"
   },
   "source": [
    "## Question 6 (Gradient descent) (Mark: 2 points)\n",
    "\n",
    "Consider the Gradient descent (GD) algorithm:\n",
    "$$ \\boldsymbol{x}_{t+1} = \\boldsymbol{x}_t - \\alpha_t \\nabla f(\\boldsymbol{x}_t), $$\n",
    "where $\\boldsymbol{x}_t \\in \\mathbb{R}^n$ is the variable vector at the $t$-th iteration and $\\alpha_t$ is the step size. In this question, we investigate the impact of the step size $\\alpha_t$ adopted in the GD algorithm. Consider the following two objective functions:\n",
    "1. Quadratic function: $ f(x_1,x_2) = x_1^2 + x_1 + 2x_2^2 $.\n",
    "2. Non-convex function: $ f(x_1,x_2) = \\sin(x_1) + 0.5x_2^2 $.\n",
    "\n",
    "Minimise them by implementing the GD algorithm, with various choices of step size as listed below:\n",
    "1. Constant step size: The step size is fixed throughout the optimization.\n",
    "2. Vanishing step size: The step size decreases over time, i.e., $ \\alpha_t = \\frac{\\alpha_0}{1 + \\lambda t} $, where $\\alpha_0$ is the initial step size, $ t $ is the iteration index and $\\lambda$ is the decay rate.\n",
    "3. Backtracking line search: The step size is updated by\n",
    "$$ \\alpha = \\beta * \\alpha $$\n",
    "as long as the following Armijo condition is satisfied\n",
    "$$ f(\\boldsymbol{x}_t - \\alpha \\nabla f(\\boldsymbol{x}_t)) > f(\\boldsymbol{x}_t) - \\frac{\\alpha}{2} \\| \\nabla f(\\boldsymbol{x}_t) \\|^2, $$\n",
    "where $0 < \\beta < 1$ is a shrinkage factor.\n",
    "\n",
    "4. Exact line search (only for the quadratic function in (1)): This finds the optimal step size at each iteration, i.e.,\n",
    "$$ \\min_{\\alpha \\geq 0} f(\\boldsymbol{x}_t - \\alpha \\nabla f(\\boldsymbol{x}_t))$$\n",
    "\n",
    "Implement GD with different choices of step size. You can experiment with different choices of parameters, and think about how to best illusrate and compare your results. For example, consider how many iterations you should run, and what stopping criterion you should take.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The minimum value of quadratic function is approaching -0.25, when $x_1=-0.5$ and $x_2=0.0$. The minimum value of non-convex function is approaching -1.0, when $x_1=-1.56$ and $x_2=0.0$.\n",
    "\n",
    "Results of the four methods:\n",
    "\n",
    "<img src=\"./figures/Q6_1.png\" width=\"75%\">\n",
    "\n",
    "### 1 Constant step size\n",
    "\n",
    "There are four parameters: step size, iterations, initial values, and stopping criterion. We change the value of $\\alpha$ (step size). If $\\alpha$ is too large, it may oscillate or even diverge; if $\\alpha$ is too small, the convergence rate is slow. For example, when the iteration is 1000 and the initial values are $x_1=x_2=0.0$, if $\\alpha$ is 1.0, the minimum value is -0.99; if $\\alpha$ is 0.0001, the minimum value is -0.08.\n",
    "\n",
    "### 2 Vanishing step size\n",
    "\n",
    "There are three additional parameters: initial step size, decay rate, and iteration index. We change the value of $\\alpha$ (step size). In the early stage, the step size is large and the minimum value decreases rapidly. In the late stage, the step size is small and value has stable convergence.\n",
    "\n",
    "### 3 Backtracking line search\n",
    "\n",
    "There is an additional parameter: shrinkage factor $\\beta$. This method ensures sufficient decrease in each iteration by shrinking $\\alpha$ until the Armijo condition is met. Larger $\\beta$ values reduce shrinkage per step but may require more Armijo checks; smaller $\\beta$ aggressively shrink the step size, potentially slowing convergence.\n",
    "\n",
    "### 4 Exact line search\n",
    "\n",
    "Exact line search computes the optimal step size at each step by minimizing $f(x_t-\\alpha\\nabla f(x_t))$. For the quadratic function, the optimal step size has a closed-form solution derived from the Hessian, which can guarantee the steepest descent per iteration, leading to rapid convergence. However, this method can not be used for non-convex functions due to the lack of analytical solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def obj_fun_1(x1, x2):\n",
    "    return x1**2 + x1 + 2 * x2**2\n",
    "\n",
    "def obj_fun_2(x1, x2):\n",
    "    return np.sin(x1) + 0.5 * x2**2\n",
    "\n",
    "def deriv_obj_fun_1(x1, x2):\n",
    "    return (2 * x1 + 1, 4 * x2)\n",
    "\n",
    "def deriv_obj_fun_2(x1, x2):\n",
    "    return (np.cos(x1), x2)\n",
    "\n",
    "# question1\n",
    "def gradient_decs_1(n): # n is the iteration\n",
    "    alpha = 0.01 # step size\n",
    "    x1, x2 = 0, 0 # initial value\n",
    "    f1 = obj_fun_1(x1, x2)\n",
    "    for i in range(n):\n",
    "        deriv1, deriv2 = deriv_obj_fun_1(x1, x2)\n",
    "        x1 = x1 - alpha * deriv1\n",
    "        x2 = x2 - alpha * deriv2\n",
    "        f2 = obj_fun_1(x1, x2)\n",
    "        if f1 - f2 < 1e-6: # stopping criterion\n",
    "            return float(x1), float(x2), float(f2)\n",
    "        if f1 > f2:\n",
    "            f1 = f2\n",
    "    return float(x1), float(x2), float(f2)\n",
    "\n",
    "def gradient_decs_2(n):\n",
    "    alpha = 0.01\n",
    "    x1, x2 = 0, 0\n",
    "    f1 = obj_fun_2(x1, x2)\n",
    "    for i in range(n):\n",
    "        deriv1, deriv2 = deriv_obj_fun_2(x1, x2)\n",
    "        x1 = x1 - alpha * deriv1\n",
    "        x2 = x2 - alpha * deriv2\n",
    "        f2 = obj_fun_2(x1, x2)\n",
    "        if f1 - f2 < 1e-6:\n",
    "            return float(x1), float(x2), float(f2)\n",
    "        if f1 > f2:\n",
    "            f1 = f2\n",
    "    return float(x1), float(x2), float(f2)\n",
    "\n",
    "# question2\n",
    "def gradient_decs_3(n):\n",
    "    alpha_0 = 0.01 # initial step size\n",
    "    lamda = 0.01 # decay rate\n",
    "    x1, x2 = 0, 0\n",
    "    f1 = obj_fun_1(x1, x2)\n",
    "    for i in range(n):\n",
    "        deriv1, deriv2 = deriv_obj_fun_1(x1, x2)\n",
    "        alpha = alpha_0 / (1 + lamda * i)\n",
    "        x1 = x1 - alpha * deriv1\n",
    "        x2 = x2 - alpha * deriv2\n",
    "        f2 = obj_fun_1(x1, x2)\n",
    "        if f1 - f2 < 1e-6:\n",
    "            return float(x1), float(x2), float(f2)\n",
    "        if f1 > f2:\n",
    "            f1 = f2\n",
    "    return float(x1), float(x2), float(f2)\n",
    "\n",
    "def gradient_decs_4(n):\n",
    "    alpha_0 = 0.01\n",
    "    lamda = 0.01\n",
    "    x1, x2 = 0, 0\n",
    "    f1 = obj_fun_2(x1, x2)\n",
    "    for i in range(n):\n",
    "        deriv1, deriv2 = deriv_obj_fun_2(x1, x2)\n",
    "        alpha = alpha_0 / (1 + lamda * i)\n",
    "        x1 = x1 - alpha * deriv1\n",
    "        x2 = x2 - alpha * deriv2\n",
    "        f2 = obj_fun_2(x1, x2)\n",
    "        if f1 - f2 < 1e-6:\n",
    "            return float(x1), float(x2), float(f2)\n",
    "        if f1 > f2:\n",
    "            f1 = f2\n",
    "    return float(x1), float(x2), float(f2)\n",
    "\n",
    "# question3\n",
    "def gradient_decs_5(n):\n",
    "    alpha = 0.01\n",
    "    beta = 0.7 # shrinkage factor\n",
    "    x1, x2 = 0, 0\n",
    "    f1 = obj_fun_1(x1, x2)\n",
    "    for i in range(n):\n",
    "        deriv1, deriv2 = deriv_obj_fun_1(x1, x2)\n",
    "        while True:\n",
    "            x1 = x1 - alpha * deriv1\n",
    "            x2 = x2 - alpha * deriv2\n",
    "            f2 = obj_fun_1(x1, x2)\n",
    "            # Armijo condition\n",
    "            if f2 <= f1 - (alpha / 2) * (deriv1**2 + deriv2**2):\n",
    "                break\n",
    "            alpha *= beta\n",
    "        if f1 - f2 < 1e-6:\n",
    "            return float(x1), float(x2), float(f2)\n",
    "        if f1 > f2:\n",
    "            f1 = f2\n",
    "    return float(x1), float(x2), float(f2)\n",
    "\n",
    "def gradient_decs_6(n):\n",
    "    alpha = 0.01\n",
    "    beta = 0.7\n",
    "    x1, x2 = 0, 0\n",
    "    f1 = obj_fun_2(x1, x2)\n",
    "    for i in range(n):\n",
    "        deriv1, deriv2 = deriv_obj_fun_2(x1, x2)\n",
    "        while True:\n",
    "            x1 = x1 - alpha * deriv1\n",
    "            x2 = x2 - alpha * deriv2\n",
    "            f2 = obj_fun_2(x1, x2)\n",
    "            if f2 <= f1 - (alpha / 2) * (deriv1**2 + deriv2**2):\n",
    "                break\n",
    "            alpha *= beta\n",
    "        if f1 - f2 < 1e-6:\n",
    "            return float(x1), float(x2), float(f2)\n",
    "        if f1 > f2:\n",
    "            f1 = f2\n",
    "    return float(x1), float(x2), float(f2)\n",
    "\n",
    "# question4\n",
    "def gradient_decs_7(n):\n",
    "    x1, x2 = 0, 0\n",
    "    f1 = obj_fun_1(x1, x2)\n",
    "    for i in range(n):\n",
    "        deriv1, deriv2 = deriv_obj_fun_1(x1, x2)\n",
    "        \n",
    "        # line search\n",
    "        def objective(alpha):\n",
    "            x1_new = x1 - alpha * deriv1\n",
    "            x2_new = x2 - alpha * deriv2\n",
    "            return obj_fun_1(x1_new, x2_new)\n",
    "        \n",
    "        res = minimize(objective, x0 = 0, bounds = [(0, None)])\n",
    "        alpha = res.x[0] # optimal step size\n",
    "        \n",
    "        x1 = x1 - alpha * deriv1\n",
    "        x2 = x2 - alpha * deriv2\n",
    "        f2 = obj_fun_1(x1, x2)\n",
    "        if f1 - f2 < 1e-6:\n",
    "            return float(x1), float(x2), float(f2)\n",
    "        if f1 > f2:\n",
    "            f1 = f2\n",
    "    return float(x1), float(x2), float(f2)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"Constant step size (func_1): {gradient_decs_1(1000)}\")\n",
    "    print(f\"Constant step size (func_2): {gradient_decs_2(1000)}\")\n",
    "    print(f\"Vanishing step size (func_1): {gradient_decs_3(1000)}\")\n",
    "    print(f\"Vanishing step size (func_2): {gradient_decs_4(1000)}\")\n",
    "    print(f\"Backtracking line search (func_1): {gradient_decs_5(1000)}\")\n",
    "    print(f\"Backtracking line search (func_2): {gradient_decs_6(1000)}\")\n",
    "    print(f\"Exact line search (func_1): {gradient_decs_7(1000)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9lSTilrgt8wG"
   },
   "source": [
    "## Question 7 (Design problem) (Bonus mark: 2 points)\n",
    "\n",
    "The aim of this exercise is to improve your ability to identify, model, and solve optimization problems by applying mathematical techniques to real-world scenarios.\n",
    "\n",
    "Step 1. Choose a (possibly engineering-related) problem from your coursework, personal interests, or daily experiences that can be addressed through optimization.\n",
    "\n",
    "Step 2. Translate the chosen scenario into a mathematical optimization problem by:\n",
    "\n",
    "1. Defining variables: Identify the variables that can be controlled or adjusted.\n",
    "\n",
    "2. Establishing the objective function: determine the function that needs to be maximized or minimized (e.g., cost, time, efficiency).\n",
    "\n",
    "3. setting Constraints: List the limitations or requirements that must be satisfied (e.g., resource limits, safety standards).\n",
    "\n",
    "Step 3. Solve the optimization. Use a solver (e.g. via scipy) if you need to do it numerically.\n",
    "\n",
    "Your answer to this question should provide sufficient deetails to all three steps above.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1\n",
    "We want to build a rectangular place against a wall using 60 meters of fencing material. Because one side (the long side) is along the wall, we only need to build three sides:\n",
    "\n",
    "One length side $l$\n",
    "\n",
    "Two width sides $w$\n",
    "\n",
    "We want to maximize the area of the rectangle: $A=l\\cdot w$.\n",
    "\n",
    "### 2\n",
    "Variables: $l$, $w$\n",
    "\n",
    "Objective function: $A(l,w)=l\\cdot w$\n",
    "\n",
    "Constraints: $l+2w\\leq60$\n",
    "\n",
    "### 3\n",
    "\n",
    "Results of $w$ and $A$:\n",
    "\n",
    "<img src=\"./figures/Q7_2.png\" width=\"50%\">\n",
    "\n",
    "The optimal values of $w$ and $l$, the maximum value of $A$:\n",
    "\n",
    "<img src=\"./figures/Q7_1.png\" width=\"75%\">\n",
    "\n",
    "From the graphs above, we can observe that when $l=30m$ and $w=15m$, $A_{\\max}=450m^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "l = cp.Variable(pos=True)\n",
    "w = cp.Variable(pos=True)\n",
    "\n",
    "constraints = [l + 2*w <= 60]\n",
    "\n",
    "objective = cp.Maximize(l * w)\n",
    "problem = cp.Problem(objective, constraints)\n",
    "problem.solve(gp=True)\n",
    "\n",
    "print(\"Length:\", l.value)\n",
    "print(\"Width:\", w.value)\n",
    "print(\"Area:\", l.value * w.value)\n",
    "\n",
    "w = np.linspace(0.1, 30, 100)\n",
    "l = 60 - 2 * w\n",
    "A = l * w\n",
    "plt.plot(w, A, label='Area = w * (60 - 2w)')\n",
    "plt.axvline(15, color='red', linestyle='--', label='Optimal width = 15m')\n",
    "plt.axhline(450, color='green', linestyle='--', label='Max area = 450 m²')\n",
    "plt.xlabel('Width (m)')\n",
    "plt.ylabel('Area (m^2)')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
